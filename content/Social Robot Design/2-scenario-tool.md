---
date: "2025-05-07"
title: "Session 2: Scenario Tool"
ShowToc: true
TocOpen: true

---

During the session we first used the Design Tools for Innovation to categorize them as tools that could be usefull for creating scenarios. In the picture below our division can be found.

![Cards Session 2](/img/Cards-session2.jpg) 

### Research
With the options in mind we soon made the decision to combine scripts and cards since they were the ones that stood out to us. After choosing these tools we searched for scientific articles about how these tools are grounded and wrote a text about this. 

From the research it became clear that Xu et al. [1] identified several challenges with scenario-based evaluation in the field of Human Robot Interaction (HMI). These challenges include the confidence of participants with the used media, so paper paper-based tools or digital media (videos). Another problem is the lack of interactivity, which leads to a failure to capture the dynamic relationship of human–robot interactions. Scenarios also often fail to include the dynamic real-world situations, missing details and adaptability to these situations. Scenarios might fail to represent social and emotional cues in live interactions, which are of great importance in assessing human-robot interaction.

To account for these limitations, the decision was made to combine scripts with a set of prompt cards. The script can be an empty template, with lines for the robot and the human the robot interacts. This allows participants to design the scenario, turn by turn, which is similar to real conversations. The prompt cards will include different personas, locations, actions and emotions. Based on these cards, the script will be written, providing a scenario that can provide various insights. 

One of the limitations mentioned is the dynamic real-world conversations. In real life, people often wait for their turns instead of talking over each other. Robots use this turn-based logic, and using scripts as a scenario-building tool will mimic this. In scripts, clear planning of responses and events is used. Mateas and Stern [2] use scripting to manage difficult and real-time interaction between users and AI characters. This work shows how scripting can make human-computer interaction dynamic and use emotions. 

To support this, Murray and Maher [3] explore how trajectories in interactive narratives can help structure and develop behaviour-focused human-computer systems. By leveraging these principles in Human Robot Interaction, the proposed tool encourages thinking about how interactions evolve over time, not solely as isolated events. 

### Description + images
On the left side of the tool, there will be a pile of described input cards that can help build or prompt the script. To the right, you can see the templates for the script, which can be filled in while using the input cards. A benefit of this tool is that you can easily mimic and create real-life applications and determine what would work and what wouldn’t work. In both scenario’s the tool helped structure dynamic conversations between humans and robots, leveraging a turn-taking model. The use of prompt cards ensures variety and helps steer the conversation so that it is not a completely random script. The visual layout helped us in collaborating as a team, the collaboration helped identify gaps or unrealistic responses. 

One of the limitations of this tool is creating fully realistic emotional responses. This requires more nuanced input cards. This could be achieved by acting out the scenarios or providing this script as inspiration for something like improv theatre. The tool for now is focused on shorter narratives and quickly discovering if an application of a robot would seem logical or not. 

For future development, longer or evolving narratives, potentially with branching, would be needed to create more realistic stories. An addition that can be made is conflict cards, to introduce problems or tension, maybe even potential problems that can arise from interaction with the robot. This could help design scenarios that overcome these design problems. ‘Wild’ cards can also be added to involve unexpected events, to stimulate speculative thinking, and to design with the unexpected in mind. 

![Scenario](/img/ScenarioTools.png) 

### SMART 
**Specific:** Use the scenario tool to simulate conversations between users and robots in healthcare contexts (e.g., dementia care, elderly assistance). Teams of designers will collaboratively build these scripts to explore design considerations.

**Measurable:** Each session results in a full script with 2+ interaction cycles. Observations will be logged per step. At least one improvement/insight is used to help guide the iterative session. 

**Accurate:** Script entries are based on personas, environments and emotions that could be encountered in real life. The cards help guide a consistent and grounded scenario. The designer of this tool can add or remove cards to help guide the conversations for a specific scenario. 

**Realistic:** The tool reflects turn-taking and emotion-focused interaction. The scenario tool helps to map out human-robot communication patterns. 

**Time-bound:** Each scenario lasts for 20-30 minutes. The first 5 minutes are used for picking the cards. The next 10 minutes are used for the first iteration cycle, after which another 5 can be used to complete the script based on insights. The last 10 minutes can be used for group reflection and logging. 

#### Roles
- Participants: using the tool
- Observer: observing the scenario and is the creator of the case who inputs cards for the scenario

#### Case used:
ROSE As a baking robot (taken from week 1)
"Baking with ROSE"
1. What would ROSE do?
- Suggesting/creating or reading recipies based on available ingredients.
- Helps residents measure, fetch, or pass ingredients.
- Opens containers, handles the oven safely, and sets timers.
2. Preliminary Requirements:
- Recipe database tailored to dietary restrictions (e.g., low sugar).
- Integration with inventory tracking (what’s in the pantry).
- Heat-safe interaction design (robot avoids hot surfaces).
- Motor skills: needs to grip or open things
- User control: Voice activation, conversation, clear instructions.

#### Participant instructions
Welcome! In this session, you'll help us explore how people and robots might interact in everyday situations using a storytelling tool.
How it works:
1. Choose Prompt Cards from each category, you have around 5 minutes for this.
There are 4 types of cards. 
- Persona: Who is the human (e.g., elderly person, patient)?
- Context: Where is the interaction happening?
- Objective: What is the person trying to achieve?
- Emotion: How does the person feel?

2. Fill in the script template based on the chosen cars. You’ll build a short turn-by-turn dialogue between the person and the robot. Fill in each box: what the person says or does, what the robot does/says in response, and so on. Think of it like writing a scene from a play! You have around 10 minutes for this. 
Try to make the interaction realistic: how would someone in this situation speak or react? Maybe even show emotions and how the robot might respond to them.
3. We’ll ask you to reflect briefly on what felt natural or unnatural. What were the insights gained, etc? We will reflect based on the observer's notes. 

#### POEM observation framework
This session was conducted with a 3-person design team, including one user and one observer. Observations were recorded using the POEM framework and discussed in a 10-minute debrief.

![Scenario](/img/Poem-week2.png) 

#### Evaluating outcome tool performance
- Using tools with more people to make sure that discussions start happening. 
- Discussions between people would be interesting to note down, since it could provide insights on which actions a robot should or should not do, or what it does or does not say. 
- Making the cards physical, but keeping the framework online, allows for flexibility, or on a whiteboard/plastified template. 
- Would, in this case, the robot be a buddy or a complete new stranger? Does the robot build connections with its residents? 
- Maybe add guiding questions to create more depth in the scenarios 
 
#### Evaluation - what worked well: 
- The tool helped structure turn-by-turn human-robot interactions, helping visualise real-world conversations.
- The use of prompt cards (persona, context, objective, emotion) made scenario-building quick and easy. 
- Participants were able to quickly create scenarios in which ROSE could function. 
- Collaboration was enhanced through a clear layout and role division (user/observer/creator).
- The digital template offered flexibility for iteration and saving. versions digitally.
​
#### Evaluation - what worked less: 
- Emotional realism in robot responses was limited. Cards often led to functional interactions, but lacked deeper emotional responses. 
- There was some confusion about where to place selected cards, this could be changed by making clear sections where the selected cards need to be placed. 
- Scenarios remained short and linear, which limits depth and doesn't reflect the complexities of real conversations. 
​
#### Future improvements:
- Add Conflict or Wild Cards: Introduce tension or error scenarios to prompt certain reactions, recovery behaviour, or emotional support from ROSE. 
- Include different templates, maybe one with an 'if-then' option, so that conversations can be viewed from multiple directions. 
- Physical templates instead of online, if the tool is physical, people are more drawn into using the tool. 
- Guided Reflection. After the tool is used, let the observer guide the reflection using the guiding questions. (see below)
​
#### How does this translate to ROSE? Why is it unique?
- It centres on Human-Robot Interaction (HRI): This tool is designed specifically to model how people interact with a social robot. 
- It models realistic conversations between humans and robots: It uses emotion, persona, and context cards to guide design, rather than just starting a random conversation. The more focused cards make the tool suited for emotionally sensitive domains like elderly care. 
- It allows quick iteration and testing of different social scenarios: The format is simple and flexible, which allows designers to quickly explore multiple personas and situations. 
- It enables exploration of trust-building and relationship dynamics: Social robots often need to build ongoing relationships, especially in care settings. 
- It addresses social failures, not just technical ones. The tool helps uncover where things might go wrong socially, and helps identify social needs. 
​
#### Guided reflection:
- What assumptions are we making about the user’s abilities?
- Would an elderly person realistically understand the robot’s instructions?
- How does the person feel in this moment? Is that reflected in how the robot responds?
- Is the robot reacting appropriately to emotion or stress?
- Is ROSE acting more like a tool or a companion here?
- Does the flow of conversation feel natural and believable?
- Are there any awkward or unrealistic moments in the dialogue?
- What would happen if something went wrong? How would ROSE handle it?
- What does this interaction say about trust in assistive robots?
- How could this script inform the robot’s personality or communication style?
- Are there ethical issues in how the robot behaves, comforts, or instructs?

#### Outcomes regarding specific case + Link to literature:
The results from the case during the ‘tools in action’ can be found below. The cards which were picked were a resident with limited mobility, the context was a weekend baking club, and the objective was to try out a new recipe. The emotion for this context is nostalgic. 
From this scenario, we learned that the robot would need to be able to display a recipe, to generate or search for a new recipe, and display it in such a way that it follows the user’s pace. The robot also needs to assist with which steps to start, and sort of create an overview for the user. 

![Scenario](/img/week2-cards.png) 

To sum up the insights regarding this case:
1. Need for adjusted pacing and step-by-step guidance
2. Interactions that adjust based on requests from the user
3. Assistance in grabbing/taking items, without replacing user autonomy
4. Displaying information clearly and relevant to actions/requests

Insights 3 and 4 are supported by the findings of Sawik et al. [4]. Who conducted group discussions with the elderly and caregivers. These discussions revealed that social robots in elderly care must support daily tasks without compromising the feeling of autonomy, thereby maintaining independence and control. A social robot’s assistive functionalities should augment a user’s functionalities, rather than replacing their own 

Regarding insights 1 and 2, Santze and Irfan [5] investigated how turn-taking can be improved in human-robot interaction. They emphasise the importance of turn-taking aspects in conversations and the need for more natural and uninterrupted interactions. Which was also one of the insights found when using this tool. They used TurnGPT and Voice Activity Projection (VAP) to improve conversational dynamics. 

Building on this, Russel en Harte [6] focused on predictive turn-taking models, which combine speech recognition with visual cues such as head pose or gaze. This causes the robot to become more responsive and context-aware. This aligns with the second insight found during the usage of this tool. 

## Sources
[1] Q. Xu, J. Ng, O. Tan, Z. Huang, B. Tay, and T. Park, “Methodological Issues in Scenario-Based Evaluation of Human–Robot Interaction,” International Journal of Social Robotics, vol. 7, no. 2, pp. 279–291, Jul. 2014, doi: 10.1007/s12369-014-0248-9 

[2] M. Mateas, A. Stern, “Façade: An Experiment in Building a Fully-Realized Interactive Drama,” 2003. [Online]. Available: https://www.researchgate.net/publication/2590261_Facade_An_Experiment_in_Building_a_Fully-Realized_Interactive_Drama

[3] Benford and Giannachi, “Temporal trajectories in shared interactive narratives,” Apr. 2008. [Online]. Available: https://www.researchgate.net/publication/221518411_Temporal_trajectories_in_shared_interactive_narratives

[4] B. Sawik et al., “Robots for Elderly Care: Review, Multi-Criteria Optimization Model and Qualitative Case Study,” Healthcare, vol. 11, no. 9, p. 1286, Apr. 2023, doi: 10.3390/healthcare11091286.

[5] G. Skantze and B. Irfan, “Applying general turn-taking models to conversational Human-Robot interaction,” arXiv.org, Jan. 15, 2025. https://arxiv.org/abs/2501.08946

[6] S. O. Russell and N. Harte, “Visual cues enhance predictive Turn-Taking for Two-Party human interaction,” arXiv.org, May 27, 2025. https://arxiv.org/abs/2505.21043
