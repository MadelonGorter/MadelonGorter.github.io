---
date: "2025-05-12"
title: "Session 3: Expression Tool"
ShowToc: true
TocOpen: true

---

### Paper-prop-puppeteering
We tried to express emotions using a water bottle since we felt like this object does not express emotions. We taped of any visible images/cues, to limit any influence on the emotions. Our goal was to show emotions through movements with the water bottle. We were able to create several emotions with simple movements. The emotions we used are: 

- Emotion 1: Happy, water bottle turning upside down and spinning
- Emotion 2: Sad, waterbottle rolling on the side, slowly
- Emotion 3: Neutral, water bottle standing normally
- Emotion 4: Surprised, waterbottle goes through the air/is thrown into the air
- Emotion 5: Disgusted, water bottle falls on its side
- Emotion 6: Uninterested, turning the water bottle away

| Emotion 1 | Emotion 2 | Emotion 3 | Emotion 4 | Emotion 5 | Emotion 6 |
|---------|---------|---------|---------|---------|---------|
|![Emotion 1](/img/SRD-happy.png)  | ![Emotion 2](/img/SRD-sad.png)  | ![Emotion 3](/img/SRD-neutral.png)  | ![Emotion 4](/img/SRD-surprised.png)  |![Emotion 5](/img/SRD-disgusted.png) | ![Emotion 6](/img/SRD-uninterested.png) |


How fast the bottle is turning, rolling, thrown into the air etc. helps express how intense the emotion is. 

When translating these movements the aspects that work are uninterested, neutral, happy, sad. The turning of the bottle is difficult to put into a robot like ROSE since it then needs a lot of space and is then constantly turning around. 

Combining our motion with rose shows that the different emotions can be expressed in different ways:
- Neutral can be just a standing/resting pose
- Uninterested can be turning the head away
- Sad tilting the head forward and looking to the ground
- Happy head held high
- Surprised is too difficult since you need more of a lifting emotion and that is not possible
- Disgusted is also difficult since letting robot collapse is not possible 

### Description of the tool
The tool aims to determine what expressive features the robot design would require in the broad application of elderly care. It is inspired by our scenario-building tool, but now focuses on improv theatre. It helps designers understand which and how expressive behaviour affects acceptance, clarity and comfort in elderly care scenarios. The toolkit involves improv theatre rules, props and elderly care scenario cards. 

#### Cards in the toolkit
The toolkit consists of three type of cards: 
1. **Scenario cards:**
"The resident refuses to eat but seems low energy. The robot needs to act."
These contain the setting and/or information for the improv theatre scene. These include real-life elderly care situations or can be developed for specific applications. This can also be done with the scenario-building tool that was developed last week. 
2. **Conflict cards:**
Autonomy vs. safety / frustration vs. help / dignity vs. routine
These cards help define the care tension in the scenario. 
3. **Constraint cards:**
Use sound effects / No speech / limited motion
The constraint cards limit the expressive modalities allowed for the robot. Multiple constrains can be used, to test out several variations of a design. 

#### Improv theatre rules
The toolkit is used in rounds, each round requires at least three participants. One person plays the elder/user, one person the robot, and the last person is the observer.

It is allowed to include props, these can include the following:
- Small speaker to initiate sound effects
- Different textiles: plush, or harder metal materials 
- Phone / tablets to help act out certain scenarios
- General home objects, depending on the setting of the scenarios

#### Reasoning behind the toolkit
With these props and additional tools, the facilitator and actors need to keep in mind the limitations of the limitation card. A scene should not last too long, but it is up to the facilitator to end a scene. 
Reasoning behind the toolkit
The variety of cards allows for different combinations of scenarios, conflicts and constraints. The improvisation theatre can help understand how these combinations and which factors affect acceptance, comfort and enhance the user’s experience of expressiveness. 

The Care-Tension Cards + Improv Stage toolkit was made to help designers figure out how social robots can show their feelings and intentions in a respectful and clear way when working with older adults. It helps solve the problem of making robot behaviours that balance being independent, respecting dignity, and meeting care needs. Using realistic situations and limits, the toolkit combines role-playing with different ways robots can express themselves. This helps designers understand which robot actions are right, acceptable, and easy to understand during real care situations.

![Expressiveness](/img/SRD-expressiveness-tool.png) 

### SMART
**Specific:** Use improv theatre to explore the expressiveness of social robots in elderly care, by acting out scenes in which a social robot has to respond to a care scenario.

**Measurable:** Each session consists of at least one completed scene using a scenario, conflict, and constraint card. Observers note down all observations, and at least one insight is defined per session. 

**Accurate:** Scenarios used are based on real elderly care situations or on case-specific requests. Props can help acquire a higher sense of reality. 

**Realistic:** Expressiveness is explored through plausible robot functionalities, such as posture or sound effects, limited to what is possible in the real world. 

**Time-bound:** Each round lasts around 20 minutes. In which 5 minutes are used for selecting cards and props. Then 10-15 minutes for acting, and 5 minutes for debriefing. 


### Participant Instructions
Welcome! In this session, you’ll explore how expressive behaviours in social robots can shape elderly care experiences. You will act out a care scenario using cards that define the context, emotional conflict, and robot constraints.
How it works:
1. **Select Cards (5 minutes) & assign roles:**
Select a Scenario, conflict and constraint card. The leader of the session might change conflicts or constraints based on certain design objectives. Each session includes at least in actor for the robot, and one actor for the elderly person. The third participant will be the observer. 

2. **Improvise the Scene (10 - 15 minutes):**
Act out the interaction, respecting the conflict and constraint cards. Optional: Use props to help add to the acted scenes. 

3. **Reflect (5–10 minutes):**
Reflect on the acted scenario and the insights from the observer. 

### Evaluating outcome tool performance
#### Case used
The scenario card was a pre-determined case, which was a robot designed to assist in taking medicines. This tool was tested with two varying sets of constraints. The cards picked were conflict: autonomy vs routine,  with a limitation of no speech.

#### POEM observation framework
The session was conducted with three participants, including one user, one acting as the robot, and one observer. The activity explored expressive behaviour in elderly care through improv-based interaction. Observations were recorded using the POEM  framework. A 10-minute debrief followed the session to discuss key insights, user experience, and implications for robot behaviour design.
![Scenario](/img/Poem-week3.png) 

#### What worked well:
The entry to work with the tool is very low, the simplicity makes it easy for participants to engage. The improvisation also really helps with creating unexpected outcomes and small cues, which are easily overlooked in larger design processes. In addition, more unexpected results can be created by adding multiple constraints or different combinations of constraints. The improv theatre also led to spontaneous humour and engagement, which essentially added to unexpected results. 

#### What did not work well:
There was some confusion about English translations, as well as ambiguity in the language on the cars. Clearer conflicts will be needed for future iterations of the tool. Another problem arose with the tool in Figma; it was hard to revisit cards after they were selected. An overview page of the selected cards would help with the user experience of the tool. Both of these would be worthwhile future improvements of the tool. 

### Evaluating tool regarding case + link to literature 
Based on the case as described above, several insights were gathered. These insights were mostly generated due to the combination of limitations and constraints. One of these insights is that even without speech, users could interpret the intention of the robot actor through gesture, proximity, and small user-generated sound effects. For example, the robot actor leaned in slightly or moved the pill container closely. 

Similar small interactions were experienced while using the robot cat during one of the lectures. The sounds and small movements can help mimic certain actions or intentions. Similar reports can be found in the literature of Raju [1], which focused on nonverbal communication cues and trust dynamics. This research specifically focused on NAO robots, but showed promising results of increased trust and perceived empathy by using non-verbal cues in communicating intentions. 

The other insights arose due to the conflict between routine (regular reminders in this case) and autonomy (not being reminded all the time). This became evident in the physical space, so for example, the robot comes closer, moving the pills forward to help remind the user. However, if similar actions are done by a social robot, it can also lead to a feeling of loss of autonomy or independence. This is supported by AI et al. [2], who developed a deep learning approach that combines sentiment analysis with knowledge reasoning.  The study’s findings show that by integrating real-time emotional feedback, a robot can dynamically adjust its actions, even based on user sentiment. The finding during the improv scene aligns with this research, an action done by the robot is not just an action, but it can also communicate social cues. Routine reminders, like taking pills can be transformed to supportive gestures instead of pushing reminders, by incorporating this knowledge. 


### Sources
[1] S. M. T. U. Raju, “Enhancing Human-Robot Interaction in Healthcare: A Study on Nonverbal Communication Cues and Trust Dynamics with NAO Robot Caregivers,” arXiv.org, Feb. 28, 2025. https://arxiv.org/abs/2503.16469?
 
[2] Y. Ai, S. Chu, J. Wang, and N. Xu, “Enhancing Elderly Care Services through Integrated Sentiment Analysis and Knowledge Reasoning: A Deep Learning Approach,” International Journal of Cognitive Computing in Engineering, Apr. 2025, doi: 10.1016/j.ijcce.2025.04.003.

