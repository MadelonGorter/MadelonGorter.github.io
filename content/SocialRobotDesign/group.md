---
date: "2025-05-07T11:09:52+01:00"
title: "Group Work"
ShowToc: true
TocOpen: true

---
## Session 1: Design Tools
I was not present during this session and recevied no input from my group.

## Session 2: Story Building
During the session we first used the Design Tools for Innovation to categorize them as tools that could be usefull for creating scenarios. In the picture below our division can be found.

![Cards Session 2](/img/Cards-session2.jpg) 

### Existing Scenario Tools
We started by making a quick overview of the tools that were in the assignment with ChatGPT to use as a starting point for choosing the scenario tools. It provided the following overview of various scenario tools with their strengths and weaknesses. 

| Tool | Description | Strengths | Weaknesses |
|---------|---------|---------|---------|
|**Scripts** | Written dialogues or interactions between the user and the product | Fast, intuitive, and focuses on flow | Can miss spatial/contextual detail |
| **Storyboards** | Sequential images showing interaction moments | Visual highlights emotion | Time-consuming, may oversimplify |
| **Play-Acting / Role Play** | Acting out a scenario with/without props | Embodied, real-time feedback | Needs group participation, may feel awkward | 
| **Stop Motion / Animation** | Mini-films that illustrate scenarios | Engaging, repeatable, remote-friendly | Requires some media skills | 
| **Cards (e.g. IDEO Method Cards)** | Prompts or building blocks for scenario creation | Quick, accessible | Can feel generic without customisation | 
| **Digital Tools: Storyboard That, Miro, Figma, Twine** | Tools for scripting, visual layout, and branching interaction | Flexible, collaborative | Can be overwhelming or not tailored to robot-specific needs | 

### Proposed Scenario Tool
With the options in mind we soon made the decision the combine scripts and cards since they were the ones that stood out to us. After choosing these tools we searched for scientific articles about how these tools are grounded and wrote a text about this. 

From the research it became clear that Xu et al. [1] identified several challenges with scenario-based evaluation in the field of Human Robot Interaction (HMI). These challenges include the confidence of participants with the used media, so paper paper-based tools or digital media (videos). Another problem is the lack of interactivity, which leads to a failure to capture the dynamic relationship of human–robot interactions. Scenarios also often fail to include the dynamic real-world situations, missing details and adaptability to these situations. Scenarios might fail to represent social and emotional cues in live interactions, which are of great importance in assessing human-robot interaction.

To account for these limitations, the decision was made to combine scripts with a set of prompt cards. The script can be an empty template, with lines for the robot and the human the robot interacts. This allows participants to design the scenario, turn by turn, which is similar to real conversations. The prompt cards will include different personas, locations, actions and emotions. Based on these cards, the script will be written, providing a scenario that can provide various insights. 

One of the limitations mentioned is the dynamic real-world conversations. In real life, people often wait for their turns instead of talking over each other. Robots use this turn-based logic, and using scripts as a scenario-building tool will mimic this. In scripts, clear planning of responses and events is used. Mateas and Stern [2] use scripting to manage difficult and real-time interaction between users and AI characters. This work shows how scripting can make human-computer interaction dynamic and use emotions. 

To support this, Murray and Maher [3] explore how trajectories in interactive narratives can help structure and develop behaviour-focused human-computer systems. By leveraging these principles in Human Robot Interaction, the proposed tool encourages thinking about how interactions evolve over time, not solely as isolated events. 

### Developing a Scenario for the Chosen Tools
On the left side of the tool in yellow, there will be a pile of described input cards that can help build or prompt the script. To the right, you can see the templates for the script, which can be filled in while using the input cards. A benefit of this tool is that you can easily mimic and create real-life applications and determine what would work and what wouldn’t work. In both scenario’s the tool helped structure dynamic conversations between humans and robots, leveraging a turn-taking model. The use of prompt cards ensures variety and helps steer the conversation so that it is not a completely random script. The visual layout helped us in collaborating as a team, the collaboration helped identify gaps or unrealistic responses. This tool is specifically designed for relevant storytelling in Human-Computer Interaction (HCI) by offering a structured, collaborative environment to simulate and evaluate interactive scenarios between humans and robots.

![Scenario](/img/ScenarioTools.png) 

One of the limitations of this tool is creating fully realistic emotional responses. This requires more nuanced input cards. This could be achieved by acting out the scenarios or providing this script as inspiration for something like improv theatre. The tool for now is focused on shorter narratives and quickly discovering if an application of a robot would seem logical or not. For future development, longer or evolving narratives, potentially with branching, would be needed to create more realistic stories. An addition that can be made is conflict cards, to introduce problems or tension, maybe even potential problems that can arise from interaction with the robot. This could help design scenarios that overcome these design problems. ‘Wild’ cards can also be added to involve unexpected events, to stimulate speculative thinking, and to design with the unexpected in mind. 

## Session 3: Expression

### Paper-prop-puppeteering
description and observations of simple paper-prop-puppeteering

We tried to express emotions using a water bottle since we felt like this object does not express emotions. We taped of any visible images/cues, to limit any influence on the emotions. Our goal was to show emotions through movements with the water bottle. We were able to create several emotions with simple movements. The emotions we used are: 

- Emotion 1: Happy, water bottle turning upside down and spinning
- Emotion 2: Sad, waterbottle rolling on the side, slowly
- Emotion 3: Neutral, water bottle standing normally
- Emotion 4: Surprised, waterbottle goes through the air/is thrown into the air
- Emotion 5: Disgusted, water bottle falls on its side
- Emotion 6: Uninterested, turning the water bottle away

| Emotion 1 | Emotion 2 | Emotion 3 | Emotion 4 | Emotion 5 | Emotion 6 |
|---------|---------|---------|---------|---------|---------|
|![Emotion 1](/img/SRD-happy.png)  | ![Emotion 2](/img/SRD-sad.png)  | ![Emotion 3](/img/SRD-neutral.png)  | ![Emotion 4](/img/SRD-surprised.png)  |![Emotion 5](/img/SRD-disgusted.png) | ![Emotion 6](/img/SRD-uninterested.png) |


How fast the bottle is turning, rolling, thrown into the air etc. helps express how intense the emotion is. 

When translating these movements the aspects that work are uninterested, neutral, happy, sad. The turning of the bottle is difficult to put into a robot like ROSE since it then needs a lot of space and is then constantly turning around. 

Combining our motion with rose shows that the different emotions can be expressed in different ways:
- Neutral can be just a standing/resting pose
- Uninterested can be turning the head away
- Sad tilting the head forward and looking to the ground
- Happy head held high
- Surprised is too difficult since you need more of a lifting emotion and that is not possible
- Disgusted is also difficult since letting robot collapse is not possible 


### Expressiveness Tool
The Care-Tension Cards + Improv Stage toolkit was made to help designers figure out how social robots can show their feelings and intentions in a respectful and clear way when working with older adults. It helps solve the problem of making robot behaviors that balance being independent, respecting dignity, and meeting care needs. Using realistic situations and limits, the toolkit combines role-playing with different ways robots can express themselves. This helps designers understand which robot actions are right, acceptable, and easy to understand during real care situations.

#### Instructions
The exercise aims to determine what expressive features the robot design would require in the broad application of elderly care. It is inspired by our scenario-building tool, but now focuses on improv theatre. It helps designers understand which and how expressive behaviour affects acceptance, clarity and comfort in elderly care scenarios. The toolkit involves improv theatre rules, props and elderly care scenario cards. 

![Expressiveness](/img/SRD-expressiveness-tool.png) 

#### Cards in the toolkit
The toolkit consists of three type of cards: 
1. Scenario cards: "The resident refuses to eat but seems low energy. The robot needs to act."
- These contain the setting and/or information for the improv theatre scene. These include real-life elderly care situations, or can be developed for specific applications. This can also be done with the scenario building tool that was developed last week. 
2. Conflict cards: Autonomy vs. safety / frustration vs. help / dignity vs. routine
- These cards help define the care tension in the scenario. 
3. Constraint cards: Use sound effects / No speech / limited motion
- The constraint cards limit the expressive modalities allowed for the robot. Multiple constrains can be used, to test out several variations of a design. 

#### Improv theatre rules
The toolkit is used in rounds, each round requires at least three participants. One person plays the elder/user, one person the robot, and the last person is the observer.

It is allowed to include props, these can include the following:
- Small speaker to initiate sound effects
- Different textiles: plush, or harder metal materials 
- Phone / tablets to help act out certain scenarios
- General home objects, depending on the setting of the scenarios

With these props and additional tools, the facilitator and actors need to keep in mind the limitations of the limitation card. A scene should not last too long, but it is up to the facilitator to end a scene. 

## Session 4: Embodiment

### Usage of Pepper and Nao
Yes, a majority of social robotics research still uses Pepper and NAO. These robots are widely available, easy to program, and supported by a strong developer community. While newer robots like Furhat, QTrobot, and ARI are emerging, we believe after looking at some projects that Pepper and NAO remain the majority in many studies, not because they're ideal for every task, but simply because they're accessible and versatile. Despite Pepper's limited commercial success, it’s still heavily used in labs and experiments.

### Total Freedom over the Embodiment and Suitability and Matrix
If we were to have total freedom over the embodiment, the robots would be better adapted to the context in which they operate. If it better fits the needs and requirements of the context/environment, it can lead to richer interactions with the robot. The form of the robot seems to define the function in social robotics. The problem with Pepper/Nao is that it is a generalised robot that can function in various environments, without necessarily adapting its embodiment. This can lead to a mismatch in size with the user group, either too small or too big. Pepper & Nao also have limited mobility, limited facial expression, and the humanoid look is leaning towards the uncanny valley for some users. If possibilities were endless, embodiments should include more non-humanoid shapes. In addition, the size should match the environment in which they are used. So, use smaller robots for things like tabletop learning, and bigger robots for transportational functionalities. 

With all these things in mind we created a matrix for all the robots that were seen during the lecture:

| Feature/Robot        | Clicbot                      | DJI Robomaster S1           | Miko 2 Robot               | Robot Cat (VibraPurr)         | mTiny Robot                | Winky Robot                  | Anki Vector                 | Roybi Robot                 | EMO                          |
|----------------------|------------------------------|------------------------------|----------------------------|-------------------------------|----------------------------|------------------------------|-----------------------------|-----------------------------|------------------------------|
| **Picture** | ![Robot 1](/img/Clicbot.jpg) |![Robot 2](/img/dji-robomaster-s1.jpg) | ![Robot 3](/img/miko2.jpg) |![Robot 4](/img/robotcat.jpg) | ![Robot 5](/img/mtiny.jpg) | ![Robot 6](/img/winky.jpg) | ![Robot 7](/img/ankivector.jpg) | ![Robot 8](/img/roybi.jpg)| ![Robot 9](/img/emo.jpg) |
| **Size**             | Small                        | Small battlebot-like         | Small                      | Small                         | Small                      | Small and round              | Small                      | Small                      | Small                        |
| **Shape**            | Toy-like, modular            | Toy-like, tank-like          | Toy-like, rounded          | Animal, cat-like              | Toy-like, cube             | Toy-like, circular head      | Compact, cube-shaped       | Toy-like, rounded           | Toy-like, humanoid-like     |
| **Colour**           | White and grey               | Black and grey               | Blue and white             | White, grey, beige            | White with accents         | Blue, red, white             | Black with screen face     | White and pink              | Black with LED face         |
| **Face**             | One-eyed face screen         | No face                      | Screen with two eyes       | "Miauw" face                  | Two panda eyes, drawn mouth| Screen with two eyes         | Screen with two eyes       | Round screen                | Screen with color-changing eyes |
| **Mobility**         | Wheels, can move like a worm | Moves with wheels            | Small wheels               | Moves paws, rotates body      | Small wheels               | Wheels, moves head and ears  | Moves with wheels, interacts| Static                      | Walks and dances on two legs|
| **Emotion Expression** | Voice, screen, movement    | Not really, but can shoot    | Expresses emotions (various)| Moves, purrs, "miauws"        | Facial expressions, movement| Eyes, sound, movement        | Eyes, sound, movement      | Voice and eye expressions   | Dances, eyes, sound effects |
| **Context**          | STEM education, coding       | Competitive robotics         | Child learning & fun       | Elder companionship           | Preschool coding           | Child entertainment          | Home assistant             | Language learning           | Home companion              |
| **Expectation Match**| High (creativity, coding)    | High (remote-controlled action)| Moderate to high (kids)  | High (pet replacement)        | High (early education)     | Moderate (fun-focused)       | Moderate                   | Moderate (education focus)  | Moderate (novelty, companion) |


### Developing an Embodiment Design Tool
As idea we came up with a card game in which players use cards that represent real robot features. The features that are represented are appearance, capabilities, personality traits and contexts. The card game aims to build a robot that best fits the challenge.

The card types used are:

| **Card Type**           | **Description**                                 | **Examples**                                              |
|-------------------------|--------------------------------------------------|-----------------------------------------------------------|
| **Form Cards (blue)**   | Physical traits: size, shape, material, color    | Small & Round, Soft Animal, Transparent Casing           |
| **Function Cards (green)** | Capabilities: movement, sensors, expressions     | Wheels + Head Rotation, Facial Recognition, LED Eye Display |
| **Emotion Cards (red)** | Emotional expressions, personality traits        | Playful Voice, Shy Posture, Purring Sound                |
| **Context Cards (yellow)** | Usage scenarios                                 | Hospital Room, Preschool Class, Home Office              |
| **Challenge Cards (black)** | Design briefs that drive gameplay              | A robot to help anxious children, A guide in a noisy museum |

**How to Play**

**Step 1: Draw a Challenge Card**
- Example: “Design a robot for calming patients in a waiting room.”

**Step 2: Each player builds a robot**
- Choose 1 Form, 2 Function, 1 Emotion, and 1 Context card.
- Players can use real robot examples (Clicbot, Pepper, Vector, etc.) for inspiration printed on each card (or drawn randomly).

**Step 3: Describe and pitch your robot**
- Give your robot a name, describe how it looks, acts, and why it fits the challenge.
- Use storytelling or a sketch to present.

**Step 4: Vote or Judge**
- Players vote on the most creative, functional, or emotionally appropriate robot design.



## Sources
[1] Q. Xu, J. Ng, O. Tan, Z. Huang, B. Tay, and T. Park, “Methodological Issues in Scenario-Based Evaluation of Human–Robot Interaction,” International Journal of Social Robotics, vol. 7, no. 2, pp. 279–291, Jul. 2014, doi: 10.1007/s12369-014-0248-9 

[2] M. Mateas, A. Stern, “Façade: An Experiment in Building a Fully-Realized Interactive Drama,” 2003. [Online]. Available: https://www.researchgate.net/publication/2590261_Facade_An_Experiment_in_Building_a_Fully-Realized_Interactive_Drama

[3] Benford and Giannachi, “Temporal trajectories in shared interactive narratives,” Apr. 2008. [Online]. Available: https://www.researchgate.net/publication/221518411_Temporal_trajectories_in_shared_interactive_narratives
